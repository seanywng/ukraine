group_by(source) %>%
slice_max(log_odds_weighted, n = 10) %>%
ungroup(),
tf_idf_bigrams_odds %>%
filter(source %in% more_than_5) %>%
group_by(source) %>%
slice_max(tf, n = 20) %>%
ungroup(),
tf_idf_bigrams_odds %>%
filter(source %in% more_than_5) %>%
group_by(source) %>%
slice_max(tf_idf, n = 20) %>%
ungroup()
) %>%
left_join(rw %>%
select(id, link, body),
by = "id") %>%
mutate(body = str_sub(body, 1, 150),
link = createLink(link)) %>%
distinct(word, id, source, .keep_all = TRUE) %>%
arrange(desc(n), desc(tf_idf)) %>%
select(source, bigram = word, count = n, `text (1st 150 char)` = body, link, -tf_idf) %>%
datatable(filter = list(position = "top", clear = TRUE),
options = list(pageLength = 10,
scrollX = TRUE,
autoWidth = TRUE,
columnDefs = list(
list(width = "80px", targets = 1:3),
list(width = "180px", targets = 4),
list(width = "100px", targets = 5)),
search = list(regex = TRUE)
,
initComplete = htmlwidgets::JS(
"function(settings, json) {",
paste0("$(this.api().table().container()).css({'font-size': '", "8.5pt", "'});"),
"}")
),
caption = htmltools::tags$caption(style = 'caption-side: top;
text-align: center;
color:black; font-size:140% ;',
"Bigram search helper")
,
escape = FALSE)
createLink <- function(val) {
sprintf(paste0('<a href="', URLdecode(val),'" target="_blank">', substr(val, 1, 55) ,'</a>'))
}
rbind(
# Pay attention to the first one since the log-odds filtering is
# so finnicky
tf_idf_bigrams_odds %>%
filter(source %in% more_than_5) %>%
add_count(word, wt = n, name = "word_total") %>%
filter(word_total > 3) %>%
filter(!is.infinite(log_odds_weighted)) %>%
distinct(source, word, .keep_all = TRUE) %>%
group_by(source) %>%
slice_max(log_odds_weighted, n = 10) %>%
ungroup(),
tf_idf_bigrams_odds %>%
filter(source %in% more_than_5) %>%
group_by(source) %>%
slice_max(tf, n = 20) %>%
ungroup(),
tf_idf_bigrams_odds %>%
filter(source %in% more_than_5) %>%
group_by(source) %>%
slice_max(tf_idf, n = 20) %>%
ungroup()
) %>%
left_join(rw %>%
select(id, link, body),
by = "id") %>%
mutate(body = str_sub(body, 1, 150),
link = createLink(link)) %>%
distinct(word, id, source, .keep_all = TRUE) %>%
arrange(desc(n), desc(tf_idf)) %>%
select(source, bigram = word, count = n, `text (1st 150 char)` = body, link, -tf_idf) %>%
datatable(filter = list(position = "top", clear = TRUE),
options = list(pageLength = 10,
scrollX = TRUE,
autoWidth = TRUE,
columnDefs = list(
list(width = "80px", targets = 1:3),
list(width = "180px", targets = 4),
list(width = "100px", targets = 5)),
search = list(regex = TRUE)
,
initComplete = htmlwidgets::JS(
"function(settings, json) {",
paste0("$(this.api().table().container()).css({'font-size': '", "8.5pt", "'});"),
"}")
),
caption = htmltools::tags$caption(style = 'caption-side: top;
text-align: center;
color:black; font-size:140% ;',
"Bigram search helper")
,
escape = FALSE)
createLink <- function(val) {
sprintf(paste0('<a href="', URLdecode(val),'" target="_blank">', substr(val, 1, 85) ,'</a>'))
}
rbind(
# Pay attention to the first one since the log-odds filtering is
# so finnicky
tf_idf_bigrams_odds %>%
filter(source %in% more_than_5) %>%
add_count(word, wt = n, name = "word_total") %>%
filter(word_total > 3) %>%
filter(!is.infinite(log_odds_weighted)) %>%
distinct(source, word, .keep_all = TRUE) %>%
group_by(source) %>%
slice_max(log_odds_weighted, n = 10) %>%
ungroup(),
tf_idf_bigrams_odds %>%
filter(source %in% more_than_5) %>%
group_by(source) %>%
slice_max(tf, n = 20) %>%
ungroup(),
tf_idf_bigrams_odds %>%
filter(source %in% more_than_5) %>%
group_by(source) %>%
slice_max(tf_idf, n = 20) %>%
ungroup()
) %>%
left_join(rw %>%
select(id, link, body),
by = "id") %>%
left_join(rw %>% select(date, id), by = "id") %>%
mutate(body = str_sub(body, 1, 150),
link = createLink(link)) %>%
distinct(word, id, source, .keep_all = TRUE) %>%
arrange(desc(n), desc(tf_idf)) %>%
select(source,
bigram = word,
count = n,
date,
`text (1st 150 char)` = body,
link,
-tf_idf) %>%
datatable(filter = list(position = "top", clear = TRUE),
options = list(pageLength = 10,
scrollX = TRUE,
autoWidth = TRUE,
columnDefs = list(
list(width = "80px", targets = 1:4),
list(width = "180px", targets = 4),
list(width = "100px", targets = 5)),
search = list(regex = TRUE)
,
initComplete = htmlwidgets::JS(
"function(settings, json) {",
paste0("$(this.api().table().container()).css({'font-size': '", "8.5pt", "'});"),
"}")
),
caption = htmltools::tags$caption(style = 'caption-side: top;
text-align: center;
color:black; font-size:140% ;',
"Bigram search helper")
,
escape = FALSE)
rbind(
# Pay attention to the first one since the log-odds filtering is
# so finnicky
tf_idf_bigrams_odds %>%
filter(source %in% more_than_5) %>%
add_count(word, wt = n, name = "word_total") %>%
filter(word_total > 3) %>%
filter(!is.infinite(log_odds_weighted)) %>%
distinct(source, word, .keep_all = TRUE) %>%
group_by(source) %>%
slice_max(log_odds_weighted, n = 10) %>%
ungroup(),
tf_idf_bigrams_odds %>%
filter(source %in% more_than_5) %>%
group_by(source) %>%
slice_max(tf, n = 20) %>%
ungroup(),
tf_idf_bigrams_odds %>%
filter(source %in% more_than_5) %>%
group_by(source) %>%
slice_max(tf_idf, n = 20) %>%
ungroup()
) %>%
left_join(rw %>%
select(id, link, body),
by = "id") %>%
left_join(rw %>% select(date, id), by = "id") %>%
mutate(body = str_sub(body, 1, 150),
link = createLink(link),
date = ifelse(date < "2019-01-01",
"2022-06-14",
date)) %>%
distinct(word, id, source, .keep_all = TRUE) %>%
arrange(desc(n), desc(tf_idf)) %>%
select(source,
bigram = word,
count = n,
date,
`text (1st 150 char)` = body,
link,
-tf_idf) %>%
datatable(filter = list(position = "top", clear = TRUE),
options = list(pageLength = 10,
scrollX = TRUE,
autoWidth = TRUE,
columnDefs = list(
list(width = "80px", targets = 1:4),
list(width = "180px", targets = 4),
list(width = "100px", targets = 5)),
search = list(regex = TRUE)
,
initComplete = htmlwidgets::JS(
"function(settings, json) {",
paste0("$(this.api().table().container()).css({'font-size': '", "8.5pt", "'});"),
"}")
),
caption = htmltools::tags$caption(style = 'caption-side: top;
text-align: center;
color:black; font-size:140% ;',
"Bigram search helper")
,
escape = FALSE)
rbind(
# Pay attention to the first one since the log-odds filtering is
# so finnicky
tf_idf_bigrams_odds %>%
filter(source %in% more_than_5) %>%
add_count(word, wt = n, name = "word_total") %>%
filter(word_total > 3) %>%
filter(!is.infinite(log_odds_weighted)) %>%
distinct(source, word, .keep_all = TRUE) %>%
group_by(source) %>%
slice_max(log_odds_weighted, n = 10) %>%
ungroup(),
tf_idf_bigrams_odds %>%
filter(source %in% more_than_5) %>%
group_by(source) %>%
slice_max(tf, n = 20) %>%
ungroup(),
tf_idf_bigrams_odds %>%
filter(source %in% more_than_5) %>%
group_by(source) %>%
slice_max(tf_idf, n = 20) %>%
ungroup()
) %>%
left_join(rw %>%
select(id, link, body),
by = "id") %>%
left_join(rw %>% select(date, id), by = "id") %>%
mutate(body = str_sub(body, 1, 150),
link = createLink(link)) %>%
filter(date >= "2022-01-01") %>%
distinct(word, id, source, .keep_all = TRUE) %>%
arrange(desc(n), desc(tf_idf)) %>%
select(source,
bigram = word,
count = n,
date,
`text (1st 150 char)` = body,
link,
-tf_idf) %>%
datatable(filter = list(position = "top", clear = TRUE),
options = list(pageLength = 10,
scrollX = TRUE,
autoWidth = TRUE,
columnDefs = list(
list(width = "80px", targets = 1:4),
list(width = "180px", targets = 4),
list(width = "100px", targets = 5)),
search = list(regex = TRUE)
,
initComplete = htmlwidgets::JS(
"function(settings, json) {",
paste0("$(this.api().table().container()).css({'font-size': '", "8.5pt", "'});"),
"}")
),
caption = htmltools::tags$caption(style = 'caption-side: top;
text-align: center;
color:black; font-size:140% ;',
"Bigram search helper")
,
escape = FALSE)
rbind(
# Pay attention to the first one since the log-odds filtering is
# so finnicky
tf_idf_bigrams_odds %>%
filter(source %in% more_than_5) %>%
add_count(word, wt = n, name = "word_total") %>%
filter(word_total > 3) %>%
filter(!is.infinite(log_odds_weighted)) %>%
distinct(source, word, .keep_all = TRUE) %>%
group_by(source) %>%
slice_max(log_odds_weighted, n = 10) %>%
ungroup(),
tf_idf_bigrams_odds %>%
filter(source %in% more_than_5) %>%
group_by(source) %>%
slice_max(tf, n = 20) %>%
ungroup(),
tf_idf_bigrams_odds %>%
filter(source %in% more_than_5) %>%
group_by(source) %>%
slice_max(tf_idf, n = 20) %>%
ungroup()
) %>%
left_join(rw %>%
select(id, link, body),
by = "id") %>%
left_join(rw %>% select(date, id), by = "id") %>%
mutate(body = str_sub(body, 1, 150),
link = createLink(link)) %>%
filter(date >= "2022-01-01") %>%
mutate(date = format.Date(date, "%b %d")) %>%
distinct(word, id, source, .keep_all = TRUE) %>%
arrange(desc(n), desc(tf_idf)) %>%
select(source,
bigram = word,
count = n,
date,
`text (1st 150 char)` = body,
link,
-tf_idf) %>%
datatable(filter = list(position = "top", clear = TRUE),
options = list(pageLength = 10,
scrollX = TRUE,
autoWidth = TRUE,
columnDefs = list(
list(width = "80px", targets = 1:4),
list(width = "180px", targets = 4),
list(width = "100px", targets = 5)),
search = list(regex = TRUE)
,
initComplete = htmlwidgets::JS(
"function(settings, json) {",
paste0("$(this.api().table().container()).css({'font-size': '", "8.5pt", "'});"),
"}")
),
caption = htmltools::tags$caption(style = 'caption-side: top;
text-align: center;
color:black; font-size:140% ;',
"Bigram search helper -- Reliefweb Ukraine terms in 2022")
,
escape = FALSE)
rbind(
# Pay attention to the first one since the log-odds filtering is
# so finnicky
tf_idf_bigrams_odds %>%
filter(source %in% more_than_5) %>%
add_count(word, wt = n, name = "word_total") %>%
filter(word_total > 3) %>%
filter(!is.infinite(log_odds_weighted)) %>%
distinct(source, word, .keep_all = TRUE) %>%
group_by(source) %>%
slice_max(log_odds_weighted, n = 10) %>%
ungroup(),
tf_idf_bigrams_odds %>%
filter(source %in% more_than_5) %>%
group_by(source) %>%
slice_max(tf, n = 20) %>%
ungroup(),
tf_idf_bigrams_odds %>%
filter(source %in% more_than_5) %>%
group_by(source) %>%
slice_max(tf_idf, n = 20) %>%
ungroup()
) %>%
left_join(rw %>%
select(id, link, body),
by = "id") %>%
left_join(rw %>% select(date, id), by = "id") %>%
mutate(body = str_sub(body, 1, 150),
link = createLink(link)) %>%
filter(date >= "2022-01-01") %>%
distinct(word, id, source, .keep_all = TRUE) %>%
arrange(desc(n), desc(tf_idf)) %>%
select(source,
bigram = word,
count = n,
date,
`text (1st 150 char)` = body,
link,
-tf_idf) %>%
datatable(filter = list(position = "top", clear = TRUE),
options = list(pageLength = 10,
scrollX = TRUE,
autoWidth = TRUE,
columnDefs = list(
list(width = "80px", targets = 1:4),
list(width = "180px", targets = 4),
list(width = "100px", targets = 5)),
search = list(regex = TRUE)
,
initComplete = htmlwidgets::JS(
"function(settings, json) {",
paste0("$(this.api().table().container()).css({'font-size': '", "8.5pt", "'});"),
"}")
),
caption = htmltools::tags$caption(style = 'caption-side: top;
text-align: center;
color:black; font-size:140% ;',
"Bigram search helper -- Reliefweb Ukraine terms in 2022")
,
escape = FALSE)
sprintf(paste0('<a href="', URLdecode(val),'" target="_blank">', substr(val, 37, 85) ,'</a>'))
createLink <- function(val) {
sprintf(paste0('<a href="', URLdecode(val),'" target="_blank">', substr(val, 37, 85) ,'</a>'))
}
rbind(
# Pay attention to the first one since the log-odds filtering is
# so finnicky
tf_idf_bigrams_odds %>%
filter(source %in% more_than_5) %>%
add_count(word, wt = n, name = "word_total") %>%
filter(word_total > 3) %>%
filter(!is.infinite(log_odds_weighted)) %>%
distinct(source, word, .keep_all = TRUE) %>%
group_by(source) %>%
slice_max(log_odds_weighted, n = 10) %>%
ungroup(),
tf_idf_bigrams_odds %>%
filter(source %in% more_than_5) %>%
group_by(source) %>%
slice_max(tf, n = 20) %>%
ungroup(),
tf_idf_bigrams_odds %>%
filter(source %in% more_than_5) %>%
group_by(source) %>%
slice_max(tf_idf, n = 20) %>%
ungroup()
) %>%
left_join(rw %>%
select(id, link, body),
by = "id") %>%
left_join(rw %>% select(date, id), by = "id") %>%
mutate(body = str_sub(body, 1, 150),
link = createLink(link)) %>%
filter(date >= "2022-01-01") %>%
distinct(word, id, source, .keep_all = TRUE) %>%
arrange(desc(n), desc(tf_idf)) %>%
select(source,
bigram = word,
count = n,
date,
`text (1st 150 char)` = body,
link,
-tf_idf) %>%
datatable(filter = list(position = "top", clear = TRUE),
options = list(pageLength = 10,
scrollX = TRUE,
autoWidth = TRUE,
columnDefs = list(
list(width = "80px", targets = 1:4),
list(width = "180px", targets = 4),
list(width = "100px", targets = 5)),
search = list(regex = TRUE)
,
initComplete = htmlwidgets::JS(
"function(settings, json) {",
paste0("$(this.api().table().container()).css({'font-size': '", "8.5pt", "'});"),
"}")
),
caption = htmltools::tags$caption(style = 'caption-side: top;
text-align: center;
color:black; font-size:140% ;',
"Bigram search helper -- Reliefweb Ukraine terms in 2022")
,
escape = FALSE)
acled %>%
# Ultimately not necessary
# mutate(event_type = ifelse(event_type == "Protests" | event_type == "Riots",
#                            "Protests & riots",
#                            event_type)) %>%
# Filtering out the 8 events that are listed in the Black Sea
# It just makes the GIF look nicer
filter(latitude < 44.0665930)
event_type <- acled %>%
# Ultimately not necessary
# mutate(event_type = ifelse(event_type == "Protests" | event_type == "Riots",
#                            "Protests & riots",
#                            event_type)) %>%
# Filtering out the 8 events that are listed in the Black Sea
# It just makes the GIF look nicer
filter(latitude > 44.0665930) %>%
mutate(month = floor_date(event_date, "month")) %>%
mutate(month = map(month, ~ seq.Date(as.Date(.),
as.Date("2022/12/31"),
by = "month"))) %>%
unnest(month) %>%
mutate(month = format_ISO8601(month, precision = "ymd")) %>%
ggplot() +
geom_sf(data = pcode2_shape, size = 0.1, colour = "black",
alpha = 0) +
geom_point(aes(x = longitude,
y = latitude,
colour = factor(event_type),
size = fatalities)) +
# Try and figure out why scale_colour_manual doesn't work
#scale_colour_manual(values = c("#D95F02", "#7570B3", "#1B9E77", "#E7298A",
#                               "#E6AB02", "#00AFBB", "#666666", "#A6761D", "#66A61E")) +
theme_void() +
guides(colour = guide_legend(override.aes = list(size = 5), order = 1)) +
theme(legend.text = element_text(size = 11),
legend.title = element_text(face = "bold"),
plot.caption = element_text(hjust = 0.5)) +
transition_manual(month) +
labs(title = "Types of conflict events as of { current_frame }",
caption = "Data source: Armed Conflict Location & Event Data Project; acleddata.com",
colour = "Event type",
size = "Fatalities")
# You might want to lower the duration
animate(event_type, height = 1748, width = 2480, res = 150, duration = 20)
anim_save("./plots/event_type_2022.gif")
