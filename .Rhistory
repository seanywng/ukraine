install.packages("xml2")
library(xml2)
# Read in the website
base_url <- "https://reliefweb.int/updates?advanced-search=%28PC241%29_%28F10%29"
base_webpage <- read_html(url)
base_webpage <- read_html(base_url)
base_elements <- base_webpage %>%
html_elements(css = "div.package > a")
knitr::opts_chunk$set(echo = TRUE)
library(xml2)
library(rvest)
library(tidyverse)
library(lubridate)
library(magrittr)
theme_set(theme_light())
# Read in the website
base_url <- "https://reliefweb.int/updates?advanced-search=%28PC241%29_%28F10%29"
base_webpage <- read_html(base_url)
base_elements <- base_webpage %>%
html_elements(css = "div.package > a")
base_elements
base_webpage
knitr::opts_chunk$set(echo = TRUE)
library(rvest)
library(tidyverse)
library(lubridate)
library(magrittr)
theme_set(theme_light())
# Read in the website
base_url <- "https://reliefweb.int/updates?advanced-search=%28PC241%29_%28F10%29"
base_webpage <- read_html(base_url)
base_elements <- base_webpage %>%
html_elements(css = "div.package > a")
base_elements
head(html_attr(html_nodes(base_webpage, "a"), "href"))
html_attr(html_nodes(base_webpage, "a"), "href") %>% sample_n(10)
html_attr(html_nodes(base_webpage, "a"), "href")
result <- lapply(links, function(x) x %>%
read_html %>%
html_nodes("a") %>%
html_attr("href"))
links <- paste0("https://reliefweb.int/updates?advanced-search=%28PC241%29_%28F10%29&page=", 0:183)
result <- lapply(links, function(x) x %>%
read_html %>%
html_nodes("a") %>%
html_attr("href"))
f1 = function(x){
x %>% read_html() %>% html_table()
}
links <- paste0("https://reliefweb.int/updates?advanced-search=%28PC241%29_%28F10%29&page=", 0:183)
df <-  lapply(links, possibly(f1, NA))
glimpse(df)
links
f1 <-  function(x){
x %>% html_attr(html_nodes(base_webpage, "a"), "href")
}
links <- paste0("https://reliefweb.int/updates?advanced-search=%28PC241%29_%28F10%29&page=", 0:183)
df <- lapply(links, possibly(f1, NA))
glimpse(df)
x %>% html_attr(html_nodes(., "a"), "href")
f1 <-  function(x){
x %>% html_attr(html_nodes(., "a"), "href")
}
links <- paste0("https://reliefweb.int/updates?advanced-search=%28PC241%29_%28F10%29&page=", 0:183)
df <- lapply(links, possibly(f1, NA))
glimpse(df)
f1 <-  function(x){
x %>% read_html() %>%
html_attr(html_nodes(., "a"), "href")
}
links <- paste0("https://reliefweb.int/updates?advanced-search=%28PC241%29_%28F10%29&page=", 0:183)
df <- lapply(links, possibly(f1, NA))
scrape_links <- function(site) {
site %>%
read_html() %>%
html_elements("a") %>%
html_attr("href") %>%
as_tibble() %>%
filter(str_detect(value, "https://"))
}
results <-
map(links, scrape_links)
results <-
bind_rows(map(links, scrape_links))
results
results %>%
write_csv("reliefweb_ukr_links.csv")
