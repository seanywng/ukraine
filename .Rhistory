head(20) %>%
ggplot(aes(x = tf_idf,
y = fct_reorder(word, tf_idf, .fun = sum)))+
geom_col(show.legend = FALSE,
fill = "tomato") +
labs(x = "Tf-idf", y = "",
title = paste0("Tf-idf: ", filename),
subtitle = "2022-01-01 to 2023-01-01") +
tf_idf_bigrams %>%
filter(!is.infinite(log_odds_weighted)) %>%
arrange(desc(log_odds_weighted)) %>%
head(20) %>%
ggplot(aes(x = log_odds_weighted,
y = fct_reorder(word, log_odds_weighted, .fun = sum)))+
geom_col(show.legend = FALSE,
fill = "forestgreen") +
labs(x = "Log odds", y = "",
title = paste0("Log odds: ", filename),
subtitle = "2022-01-01 to 2023-01-01")
ggsave(plot = bigram_patchwork,
filename = paste0("./plots/bigram_source/",filename, ".png"),
device = "png",
dpi = 300, height = 11, width = 14, units = "in")
}
save_bigrams <- function(df, filename) {
bigram_patchwork <- df %>%
arrange(desc(tf)) %>%
head(20) %>%
ggplot(aes(x = tf,
y = fct_reorder(word, tf, .fun = sum)))+
geom_col(show.legend = FALSE,
fill = "cornflowerblue") +
labs(x = "Term frequency", y = "",
title = paste0("Term frequency: ", filename),
subtitle = "2022-01-01 to 2023-01-01") +
df %>%
arrange(desc(tf_idf)) %>%
head(20) %>%
ggplot(aes(x = tf_idf,
y = fct_reorder(word, tf_idf, .fun = sum)))+
geom_col(show.legend = FALSE,
fill = "tomato") +
labs(x = "Tf-idf", y = "",
title = paste0("Tf-idf: ", filename),
subtitle = "2022-01-01 to 2023-01-01") +
df %>%
filter(!is.infinite(log_odds_weighted)) %>%
arrange(desc(log_odds_weighted)) %>%
head(20) %>%
ggplot(aes(x = log_odds_weighted,
y = fct_reorder(word, log_odds_weighted, .fun = sum)))+
geom_col(show.legend = FALSE,
fill = "forestgreen") +
labs(x = "Log odds", y = "",
title = paste0("Log odds: ", filename),
subtitle = "2022-01-01 to 2023-01-01")
ggsave(plot = bigram_patchwork,
filename = paste0("./plots/bigram_source/",filename, ".png"),
device = "png",
dpi = 300, height = 11, width = 14, units = "in")
}
tf_idf_bigrams %>%
nest(-source) %$%
walk2(data, source, save_bigrams)
# Article checking function
rw %>%
filter(source == "WFP" & str_detect(body, "clearing agent")) %>%
sample_n(1) %>%
pull(body, id)
# Article checking function
rw %>%
filter(source == "WFP" & str_detect(body, "agency convoys")) %>%
sample_n(1) %>%
pull(body, id)
# This one doesn't work anymore since you stripped out the ID
rw %>%
filter(id ==
tf_idf_bigrams %>%
filter(source == "NRC" & bigram == "poorly insulated") %>%
sample_n(1) %>%
pull(id)) %>%
pull(body, date)
tf_idf_bigrams
tf_idf_bigrams %>%
filter(source == "NRC" & bigram == "poorly insulated") %>%
sample_n(1) %>%
pull(id)
tf_idf_bigrams
# This one doesn't work anymore since you stripped out the ID
rw %>%
filter(id ==
tf_idf_bigrams %>%
filter(source == "NRC" & word == "poorly insulated") %>%
sample_n(1) %>%
pull(id)) %>%
pull(body, date)
library(profvis)
# Article checking function
profvis{rw %>%
library(profvis)
# Article checking function
profvis{rw %>%
# Article checking function
profvis({rw %>%
filter(source == "WFP" & str_detect(body, "agency convoys")) %>%
sample_n(1) %>%
pull(body, id)})
# alternative that uses id
profvis({rw %>%
filter(id ==
tf_idf_bigrams %>%
filter(source == "WFP" & word == "agency convoys") %>%
sample_n(1) %>%
pull(id)) %>%
pull(body, date)})
rw %>%
filter(source == "USAID" & str_detect(tolower(body), "bakhmut")) %>%
sample_n(1) %>%
pull(body, id)
profvis({rw %>%
filter(source == "USAID" & str_detect(tolower(body), "bakhmut")) %>%
sample_n(1) %>%
pull(body, id)})
profvis({rw %>%
# Including tolower has significantly impacted performance
filter(source == "USAID" & str_detect(body, "bakhmut")) %>%
sample_n(1) %>%
pull(body, id)})
profvis({rw %>%
# Including tolower has significantly impacted performance
filter(source == "USAID" & str_detect(body, "Bakhmut")) %>%
sample_n(1) %>%
pull(body, id)})
rw %>%
# Including tolower has significantly impacted performance
filter(source == "US DOS" & str_detect(body, "global partnerships")) %>%
sample_n(1) %>%
pull(body, id)
rw %>%
# Including tolower has significantly impacted performance
filter(source == "US DOS" & str_detect(body, "law enforcement")) %>%
sample_n(1) %>%
pull(body, id)
rw %>%
# Including tolower has significantly impacted performance
filter(source == "US DOS" & str_detect(body, "individual giving")) %>%
sample_n(1) %>%
pull(body, id)
rw %>%
# Including tolower has significantly impacted performance
filter(source == "UNOSAT" & str_detect(body, "complete count")) %>%
sample_n(1) %>%
pull(body, id)
rw %>%
# Including tolower has significantly impacted performance
filter(source == "UNOSAT" & str_detect(body, "complete count")) %>%
sample_n(1) %>%
pull(body, id)
ukr_links %>% filter(url == 2094)
ukr_links
ukr_links %>% filter(id == 2094)
ukr_links %>% filter(id == 2094) %>% pull(url)
rw %>%
# Including tolower has significantly impacted performance
filter(source == "UNFPA" & str_detect(body, "Action Plan")) %>%
sample_n(1) %>%
pull(body, id)
rw %>%
filter(id ==
tf_idf %>%
filter(source == "ACAPS" & word == "slipping") %>%
sample_n(1) %>%
pull(id)) %>%
pull(body)
rw %>%
# Including tolower has significantly impacted performance
filter(source == "UNFPA" & str_detect(body, "Action Plan")) %>%
sample_n(1) %>%
pull(body, id)
rw %>%
# Including tolower has significantly impacted performance
filter(source == "UNFPA" & str_detect(body, "Action Plan")) %>%
sample_n(1) %>%
pull(body, title)
rw %>%
# Including tolower has significantly impacted performance
filter(source == "UNFPA" & str_detect(body, "Action Plan")) %>%
sample_n(1) %>%
pull(body, title)
rw %>%
filter(id ==
tf_idf %>%
filter(source == "ACAPS" & word == "slipping") %>%
sample_n(1) %>%
pull(id)) %>%
pull(body)
knitr::opts_chunk$set(echo = FALSE, fig.width=9, message = FALSE, warning=FALSE)
library(tidyverse)
library(tidytext)
library(tidymodels)
library(broom)
library(ggraph)
library(tidylo)
library(widyr)
library(janitor)
library(lubridate)
library(SnowballC)
library(magrittr)
library(patchwork)
library(tidylo)
library(DT)
`%out%` <- Negate(`%in%`)
theme_set(theme_light())
ukr_links <- read_csv("./data/reliefweb_ukr_links.csv") %>%
rename(url = value) %>%
mutate(id = row_number())
# This is the list of Spanish and French links
to_remove <- read_csv("./data/links_to_remove.csv") %>%
rename(url = value) %>%
pull(url)
rw <- read_csv("./data/scraped_full_20230101_20220101.csv") %>%
mutate(date = dmy(date)) %>%
left_join(ukr_links, by = c("link" = "url")) %>%
filter(link %out% to_remove) %>%
select(-link) %>%
mutate(theme = str_replace_all(theme, "\n", ",")) %>%
mutate(agriculture = ifelse(str_detect(theme, "Agriculture"), 1, 0),
cccm = ifelse(str_detect(theme, "Camp Coordination and Camp Management"), 1, 0),
cca = ifelse(str_detect(theme, "Climate Change and Environment"), 1, 0),
contributions = ifelse(str_detect(theme, "Contributions"), 1, 0),
coordination = ifelse(str_detect(theme, "Coordination"), 1, 0),
disaster_management = ifelse(str_detect(theme, "Disaster Management"), 1, 0),
education = ifelse(str_detect(theme, "Education"), 1, 0),
food_nutrition = ifelse(str_detect(theme, "Food and Nutrition"), 1, 0),
gender = ifelse(str_detect(theme, "Gender"), 1, 0),
health = ifelse(str_detect(theme, "Health"), 1, 0),
hiv_aids = ifelse(str_detect(theme, "HIV/Aids"), 1, 0),
financing = ifelse(str_detect(theme, "Humanitarian Financing"), 1, 0),
logs_telecoms = ifelse(str_detect(theme, "Logistics and Telecommunications"), 1, 0),
mine_action = ifelse(str_detect(theme, "Mine Action"), 1, 0),
peacebuiling = ifelse(str_detect(theme, "Peacekeeping and Peacebuilding"), 1, 0),
protection_human_rights = ifelse(str_detect(theme, "Protection and Human Rights"), 1, 0),
recovery = ifelse(str_detect(theme, "Recovery and Reconstruction"), 1, 0),
security = ifelse(str_detect(theme, "Safety and Security"), 1, 0),
shelter_nfi = ifelse(str_detect(theme, "Shelter and Non-Food Items"), 1, 0),
wash = ifelse(str_detect(theme, "Water Sanitation Hygiene"), 1, 0))
# I don't think this is necessary anymore, I'm just going to treat this like
# genres in an IMDB scrape
# rw_dup <- rw %>%
#   separate_rows(theme,
#            sep = "\n")
rw <- read_csv("./data/scraped_full_20230101_20220101.csv") %>%
mutate(date = dmy(date),
month = month(date)) %>%
left_join(ukr_links, by = c("link" = "url")) %>%
filter(link %out% to_remove) %>%
select(-link) %>%
mutate(theme = str_replace_all(theme, "\n", ",")) %>%
mutate(agriculture = ifelse(str_detect(theme, "Agriculture"), 1, 0),
cccm = ifelse(str_detect(theme, "Camp Coordination and Camp Management"), 1, 0),
cca = ifelse(str_detect(theme, "Climate Change and Environment"), 1, 0),
contributions = ifelse(str_detect(theme, "Contributions"), 1, 0),
coordination = ifelse(str_detect(theme, "Coordination"), 1, 0),
disaster_management = ifelse(str_detect(theme, "Disaster Management"), 1, 0),
education = ifelse(str_detect(theme, "Education"), 1, 0),
food_nutrition = ifelse(str_detect(theme, "Food and Nutrition"), 1, 0),
gender = ifelse(str_detect(theme, "Gender"), 1, 0),
health = ifelse(str_detect(theme, "Health"), 1, 0),
hiv_aids = ifelse(str_detect(theme, "HIV/Aids"), 1, 0),
financing = ifelse(str_detect(theme, "Humanitarian Financing"), 1, 0),
logs_telecoms = ifelse(str_detect(theme, "Logistics and Telecommunications"), 1, 0),
mine_action = ifelse(str_detect(theme, "Mine Action"), 1, 0),
peacebuiling = ifelse(str_detect(theme, "Peacekeeping and Peacebuilding"), 1, 0),
protection_human_rights = ifelse(str_detect(theme, "Protection and Human Rights"), 1, 0),
recovery = ifelse(str_detect(theme, "Recovery and Reconstruction"), 1, 0),
security = ifelse(str_detect(theme, "Safety and Security"), 1, 0),
shelter_nfi = ifelse(str_detect(theme, "Shelter and Non-Food Items"), 1, 0),
wash = ifelse(str_detect(theme, "Water Sanitation Hygiene"), 1, 0))
bigrams_month <- rw %>%
filter(source %out% c("IAEA", "ACLED", "OSCE")) %>%
select(id, month, body) %>%
unnest_tokens(bigram, body, token = "ngrams", n = 2) %>%
filter(!is.na(bigram)) %>%
separate(bigram, c("word1", "word2"), sep = " ") %>%
filter(!word1 %in% stop_words$word & (nchar(word1) < 20)) %>%
filter(!word2 %in% stop_words$word & (nchar(word2) < 20)) %>%
filter(str_detect(word1, "[a-z]") & !str_detect(word1, "<")) %>%
filter(str_detect(word2, "[a-z]") & !str_detect(word2, "<")) %>%
unite(bigram, word1, word2, sep = " ")
tf_idf_bigram_months <- bigrams_month %>%
count(id, bigram) %>%
bind_tf_idf(bigram, id, n) %>%
bind_log_odds(bigram, id, n) %>%
arrange(desc(tf_idf)) %>%
left_join(rw %>%
select(id, source),
by = "id") %>%
filter(bigram %out% c("million people", "humanitarian assistance")) %>%
rename(word = bigram)
tf_idf_bigram_months
tf_idf_bigram_months <- bigrams_month %>%
count(month, bigram) %>%
bind_tf_idf(bigram, month, n) %>%
bind_log_odds(bigram, month, n) %>%
arrange(desc(tf_idf)) %>% %>%
tf_idf_bigram_months <- bigrams_month %>%
count(month, bigram) %>%
bind_tf_idf(bigram, month, n) %>%
bind_log_odds(bigram, month, n) %>%
arrange(desc(tf_idf)) %>%
filter(bigram %out% c("million people", "humanitarian assistance")) %>%
rename(word = bigram)
tf_idf_bigram_months
tf_idf_bigram_months %>%
ggplot(aes(x = n)) +
geom_histogram()
tf_idf_bigram_months %>%
ggplot(aes(x = n)) +
geom_histogram() +
scale_x_log10()
tf_idf_bigram_months %>%
ggplot(aes(x = n)) +
geom_histogram() +
scale_x_log10() +
scale_y_log10()
tf_idf_bigram_months %>%
ggplot(aes(x = n)) +
geom_histogram() +
scale_x_log10() +
scale_y_log10() +
geom_vline(xintercept = 2, lty = 2, colour = "red") +
geom_vline(xintercept = 3, lty = 2, colour = "orange")
tf_idf_bigram_months <- bigrams_month %>%
count(month, bigram) %>%
bind_tf_idf(bigram, month, n) %>%
bind_log_odds(bigram, month, n) %>%
arrange(desc(tf_idf)) %>%
filter(bigram %out% c("million people", "humanitarian assistance")) %>%
rename(word = bigram) %>%
filter(n > 2)
bigrams <- rw %>%
# You're filtering out one clump here
# filter(source %out% c("IAEA", "ACLED")) %>%
select(source, id, body) %>%
unnest_tokens(bigram, body, token = "ngrams", n = 2) %>%
filter(!is.na(bigram)) %>%
separate(bigram, c("word1", "word2"), sep = " ") %>%
filter(!word1 %in% stop_words$word & (nchar(word1) < 20)) %>%
filter(!word2 %in% stop_words$word & (nchar(word2) < 20)) %>%
filter(str_detect(word1, "[a-z]") & !str_detect(word1, "<")) %>%
filter(str_detect(word2, "[a-z]") & !str_detect(word2, "<")) %>%
unite(bigram, word1, word2, sep = " ")
tf_idf_bigrams <- bigrams %>%
count(id, bigram) %>%
bind_tf_idf(bigram, id, n) %>%
bind_log_odds(bigram, id, n) %>%
arrange(desc(tf_idf)) %>%
left_join(rw %>%
select(id, source),
by = "id") %>%
filter(bigram %out% c("million people", "humanitarian assistance")) %>%
rename(word = bigram)
tf_idf_bigrams %>%
ggplot(aes(x = n)) +
geom_histogram() +
scale_x_log10() +
scale_y_log10() +
geom_vline(xintercept = 2, lty = 2, colour = "red") +
geom_vline(xintercept = 3, lty = 2, colour = "orange")
tf_idf_bigram_months %>%
ggplot(aes(x = n)) +
geom_histogram() +
scale_x_log10() +
scale_y_log10() +
geom_vline(xintercept = 2, lty = 2, colour = "red") +
geom_vline(xintercept = 3, lty = 2, colour = "orange")
tf_idf_bigrams %>%
ggplot(aes(x = n)) +
geom_histogram() +
scale_x_log10() +
scale_y_log10() +
geom_vline(xintercept = 2, lty = 2, colour = "red") +
geom_vline(xintercept = 3, lty = 2, colour = "orange")
tf_idf_bigrams <- bigrams %>%
count(id, bigram) %>%
bind_tf_idf(bigram, id, n) %>%
bind_log_odds(bigram, id, n) %>%
arrange(desc(tf_idf)) %>%
left_join(rw %>%
select(id, source),
by = "id") %>%
filter(bigram %out% c("million people", "humanitarian assistance")) %>%
rename(word = bigram) %>%
filter(n > 3)
save_bigrams <- function(df, filename) {
bigram_patchwork <- df %>%
arrange(desc(tf)) %>%
head(20) %>%
ggplot(aes(x = tf,
y = fct_reorder(word, tf, .fun = sum)))+
geom_col(show.legend = FALSE,
fill = "cornflowerblue") +
labs(x = "Term frequency", y = "",
title = paste0("Term frequency: ", filename),
subtitle = "2022-01-01 to 2023-01-01") +
df %>%
arrange(desc(tf_idf)) %>%
head(20) %>%
ggplot(aes(x = tf_idf,
y = fct_reorder(word, tf_idf, .fun = sum)))+
geom_col(show.legend = FALSE,
fill = "tomato") +
labs(x = "Tf-idf", y = "",
title = paste0("Tf-idf: ", filename),
subtitle = "2022-01-01 to 2023-01-01") +
df %>%
filter(!is.infinite(log_odds_weighted)) %>%
arrange(desc(log_odds_weighted)) %>%
head(20) %>%
ggplot(aes(x = log_odds_weighted,
y = fct_reorder(word, log_odds_weighted, .fun = sum)))+
geom_col(show.legend = FALSE,
fill = "forestgreen") +
labs(x = "Log odds", y = "",
title = paste0("Log odds: ", filename),
subtitle = "2022-01-01 to 2023-01-01")
ggsave(plot = bigram_patchwork,
filename = paste0("./plots/bigram_source/",filename, ".png"),
device = "png",
dpi = 300, height = 11, width = 14, units = "in")
}
# Throws an error, but still works
# This error occurs when you ask R to overwrite an existing file
tf_idf_bigrams %>%
nest(-source) %$%
walk2(data, source, save_bigrams)
tf_idf_bigrams <- bigrams %>%
count(id, bigram) %>%
bind_tf_idf(bigram, id, n) %>%
bind_log_odds(bigram, id, n) %>%
arrange(desc(tf_idf)) %>%
left_join(rw %>%
select(id, source),
by = "id") %>%
filter(bigram %out% c("million people", "humanitarian assistance")) %>%
rename(word = bigram) %>%
filter(n > 2)
# Throws an error, but still works
# This error occurs when you ask R to overwrite an existing file
tf_idf_bigrams %>%
nest(-source) %$%
walk2(data, source, save_bigrams)
rw %>%
count(source, sort = TRUE)
rw %>%
count(source, sort = TRUE) %>%
filter(n >= 5)
more_than_5 <- rw %>%
count(source, sort = TRUE) %>%
filter(n >= 5)
# Throws an error, but still works
# This error occurs when you ask R to overwrite an existing file
tf_idf_bigrams %>%
filter(source %in% more_than_5) %>%
nest(-source) %$%
walk2(data, source, save_bigrams)
more_than_5 <- rw %>%
count(source, sort = TRUE) %>%
filter(n >= 5) %>%
select(source)
# Throws an error, but still works
# This error occurs when you ask R to overwrite an existing file
tf_idf_bigrams %>%
filter(source %in% more_than_5) %>%
nest(-source) %$%
walk2(data, source, save_bigrams)
tf_idf_bigrams %>%
filter(source %in% more_than_5)
more_than_5
more_than_5 <- rw %>%
count(source, sort = TRUE) %>%
filter(n >= 5) %>%
pull(source)
# Throws an error, but still works
# This error occurs when you ask R to overwrite an existing file
tf_idf_bigrams %>%
filter(source %in% more_than_5) %>%
nest(-source) %$%
walk2(data, source, save_bigrams)
rw %>%
count(source, sort = TRUE) %>%
filter(n >= 5)
tf_idf_bigram_months <- bigrams_month %>%
count(month, bigram) %>%
bind_tf_idf(bigram, month, n) %>%
bind_log_odds(bigram, month, n) %>%
arrange(desc(tf_idf)) %>%
filter(bigram %out% c("million people", "humanitarian assistance")) %>%
rename(word = bigram) %>%
filter(n > 1)
# Throws an error, but still works
# This error occurs when you ask R to overwrite an existing file
tf_idf_bigrams %>%
filter(source %in% more_than_5) %>%
nest(-source) %$%
walk2(data, source, save_bigrams)
# Throws an error, but still works
# This error occurs when you ask R to overwrite an existing file
tf_idf_bigrams %>%
filter(source %in% more_than_5) %>%
nest(-source) %$%
walk2(data, source, save_bigrams)
