---
title: "Untitled"
output: html_document
date: '2023-01-06'
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = FALSE, fig.width=9, message = FALSE, warning=FALSE)

library(tidyverse)
library(tidytext)
library(tidymodels)
library(broom)
library(ggraph)
library(tidylo)
library(widyr)
library(janitor)
library(lubridate)
library(SnowballC)
library(magrittr)
library(patchwork)

`%out%` <- Negate(`%in%`)

```


## Data

```{r}

ukr_links <- read_csv("./data/reliefweb_ukr_links.csv") %>% 
  rename(url = value) %>% 
  mutate(id = row_number())

# This is the list of Spanish and French links 
to_remove <- read_csv("./data/links_to_remove.csv") %>% 
  rename(url = value) %>% 
  pull(url)

rw <- read_csv("./data/scraped_full_20230101_20220101.csv") %>% 
  mutate(date = dmy(date)) %>% 
  left_join(ukr_links, by = c("link" = "url")) %>%
  filter(link %out% to_remove) %>% 
  select(-link) %>% 
  mutate(theme = str_replace_all(theme, "\n", ",")) %>% 
  mutate(agriculture = ifelse(str_detect(theme, "Agriculture"), 1, 0), 
         cccm = ifelse(str_detect(theme, "Camp Coordination and Camp Management"), 1, 0),
         cca = ifelse(str_detect(theme, "Climate Change and Environment"), 1, 0),
         contributions = ifelse(str_detect(theme, "Contributions"), 1, 0),
         coordination = ifelse(str_detect(theme, "Coordination"), 1, 0),
         disaster_management = ifelse(str_detect(theme, "Disaster Management"), 1, 0),
         education = ifelse(str_detect(theme, "Education"), 1, 0),
         food_nutrition = ifelse(str_detect(theme, "Food and Nutrition"), 1, 0),
         gender = ifelse(str_detect(theme, "Gender"), 1, 0),
         health = ifelse(str_detect(theme, "Health"), 1, 0),
         hiv_aids = ifelse(str_detect(theme, "HIV/Aids"), 1, 0),
         financing = ifelse(str_detect(theme, "Humanitarian Financing"), 1, 0),
         logs_telecoms = ifelse(str_detect(theme, "Logistics and Telecommunications"), 1, 0),
         mine_action = ifelse(str_detect(theme, "Mine Action"), 1, 0),
         peacebuiling = ifelse(str_detect(theme, "Peacekeeping and Peacebuilding"), 1, 0),
         protection_human_rights = ifelse(str_detect(theme, "Protection and Human Rights"), 1, 0),
         recovery = ifelse(str_detect(theme, "Recovery and Reconstruction"), 1, 0), 
         security = ifelse(str_detect(theme, "Safety and Security"), 1, 0),
         shelter_nfi = ifelse(str_detect(theme, "Shelter and Non-Food Items"), 1, 0),
         wash = ifelse(str_detect(theme, "Water Sanitation Hygiene"), 1, 0))

# I don't think this is necessary anymore, I'm just going to treat this like 
# genres in an IMDB scrape 
# rw_dup <- rw %>% 
#   separate_rows(theme, 
#            sep = "\n")


```

## Titles 

```{r}
titles <- rw %>% 
  select(id, title) %>% 
  unnest_tokens(word, title) %>% 
  count(id, word, sort = TRUE) %>% 
  anti_join(stop_words, by = "word") %>% 
  mutate(word = str_remove_all(word, "'")) %>% 
  mutate(stem = wordStem(word, language = "porter")) %>% 
  filter(stem %out% c("de", "des", "la", "las", "le", "les", 
                      "en", "el", "http", "se", "ses")) %>% 
  mutate(stem = recode(stem, 
                       "ukraine’" = "ukrain")) %>% 
  filter(nchar(stem) < 20)
  
```


```{r}
set.seed(2023)

titles %>% 
  pairwise_count(word, id, sort = TRUE, upper = FALSE) %>%
  filter(str_detect(item1, "[a-z]") & str_detect(item2, "[a-z]")) %>%
  filter(n >= 70) %>%
  igraph::graph_from_data_frame() %>% 
  ggraph(layout = "lgl") +
  geom_edge_link(aes(edge_alpha = n, edge_width = n), edge_colour = "cyan4") +
  geom_node_point(size = 2) +
  geom_node_text(aes(label = name), repel = TRUE, size = 3, 
                 point.padding = unit(0.2, "lines")) +
  theme_void()

```


## Words 

```{r}

words <- rw %>% 
  select(id, body) %>% 
  unnest_tokens(word, body) %>% 
  count(id, word, sort = TRUE) %>% 
  anti_join(stop_words, by = "word") %>% 
  filter(str_detect(word, "[a-z]")) %>%
  mutate(word = str_remove_all(word, "'")) %>% 
  mutate(stem = wordStem(word, language = "porter")) %>% 
  filter(stem %out% c("de", "des", "la", "las", "le", "les", 
                      "en", "el", "http", "se", "ses")) %>% 
  filter(!str_detect(word, "ukraine|ukrainian|people|humanitarian|support|including|country")) %>% 
  mutate(stem = recode(stem, 
                       "ukraine’" = "ukrain")) %>% 
  filter(nchar(stem) < 20)


```

```{r}
set.seed(2023)

word_pairs <- words %>% 
  pairwise_count(word, id, sort = TRUE, upper = FALSE) %>%
  filter(str_detect(item1, "[a-z]") & str_detect(item2, "[a-z]")) %>% 
  
  filter(n >= 500)

word_pairs %>% 
  igraph::graph_from_data_frame() %>% 
  ggraph(layout = "lgl") +
  geom_edge_link(aes(edge_alpha = n, edge_width = n), edge_colour = "darkred") +
  geom_node_point(size = 2) +
  geom_node_text(aes(label = name), repel = TRUE, size = 3, 
                 point.padding = unit(0.2, "lines")) +
  theme_void()
  
word_pairs %>% 
  filter(n >= 800) %>% 
  arrange(desc(n))
```


### Tf-idf 

```{r}
tf_idf <- words %>% 
  left_join(rw %>% select(id, source, theme), 
            by = "id") %>% 
  bind_tf_idf(stem, source, n) 

tf_idf %>%
  group_by(source) %>% 
  filter(source %in% c("ICRC", "OCHA", "UNHCR", "UNICEF", 
                       "OHCHR", "ECHO")) %>% 
  slice_max(tf_idf, n = 20) %>% 
  ungroup() %>% 
  ggplot(aes(x = tf_idf, 
             y = reorder_within(stem, tf_idf, source, fun = sum), 
             fill = source))+ 
  geom_col(show.legend = FALSE) + 
  facet_wrap(~ source, scales = "free") + 
  scale_y_reordered() + 
  labs(x = "Term frequency", y = "")
  
tf_idf %>% 
  filter(source == "World Vision") %>% 
  count(stem, sort = TRUE)
  
top_40 <- rw %>% 
  count(source, sort = TRUE) %>% 
  filter(n >= 25) %>% 
  pull(source)

top_10 <- rw %>% 
  count(theme, sort = TRUE) %>% 
  filter(n >= 25) %>% 
  pull(source)

ukr_words %>% 
  filter(stem == "hiroshima")


```

```{r}

selection <- "ACLED"

tf_idf %>%
  group_by(source) %>% 
  filter(source == selection) %>% 
  slice_max(tf, n = 20) %>% 
  ungroup() %>% 
  ggplot(aes(x = tf, 
             y = reorder_within(stem, tf, source, fun = sum),))+ 
  geom_col(show.legend = FALSE, 
           fill = "cornflowerblue") + 
  facet_wrap(~ source, scales = "free") + 
  scale_y_reordered() + 
  labs(x = "Term frequency", y = "") + 

tf_idf %>%
  group_by(source) %>% 
  filter(source == selection) %>% 
  slice_max(tf_idf, n = 20) %>% 
  ungroup() %>% 
  ggplot(aes(x = tf_idf, 
             y = reorder_within(stem, tf_idf, source, fun = sum),))+ 
  geom_col(show.legend = FALSE, 
           fill = "tomato") + 
  facet_wrap(~ source, scales = "free") + 
  scale_y_reordered() + 
  labs(x = "Tf-idf", y = "") 
```

```{r}

# Article checking function

rw %>% 
  filter(id == 
           tf_idf %>%
           filter(source == "ACLED" & stem == "lgbt") %>%
           sample_n(1) %>%
           pull(id)) %>%
  pull(body)
```



### Thesis 
So, you'll wanna dig around to see where the acled dataset and the humanitarian text mining intersect -- likely some large bombings and the mentions of mine action. 

## Bigrams


```{r}
  bigrams_raw <- tbl %>% 
    select(id, body) %>% 
    unnest_tokens(bigram, body, token = "ngrams", n = 2) %>% 
    filter(!is.na(bigram))
  
  bigrams_sep <- bigrams_raw %>% 
    separate(bigram, c("word1", "word2"), sep = " ") %>% 
    filter(!word1 %in% stop_words$word & (nchar(word1) < 20)) %>% 
    filter(!word2 %in% stop_words$word & (nchar(word2) < 20)) %>% 
    filter(str_detect(word1, "[a-z]") & !str_detect(word1, "<")) %>% 
    filter(str_detect(word2, "[a-z]") & !str_detect(word2, "<"))
  
  bigram_counts <- bigrams_sep %>% count(word1, word2, sort = TRUE)
  
  bigrams <- bigrams_sep %>% 
    unite(bigram, word1, word2, sep = " ")
  
  tf_idf_bi <- bigrams %>% 
    count(id, bigram) %>% 
    bind_tf_idf(bigram, id, n) %>% 
    arrange(desc(tf_idf))

```


```{r}
set.seed(2023)

network_graph <- bigrams %>% 
  filter(bigram %out% c("million people", 
                        "internally displaced", 
                        "united nations", 
                        "human rights", 
                        "humanitarian assistance", 
                        "february 2022")) %>% 
  distinct(id, bigram) %>% 
  add_count(bigram) %>% 
  filter(n >= 50) %>% 
  pairwise_cor(bigram, id, sort = TRUE) %>% 
  filter(correlation >= .3) %>% 
  igraph::graph_from_data_frame() %>% 
  ggraph(layout = "stress") + 
  geom_edge_link(aes(alpha = correlation), 
                 colour = "blue", 
                 check_overlap = TRUE) + 
  scale_alpha_continuous(range = c(.1, .4)) + 
  geom_node_point(colour = "blue", alpha = .1) + 
  geom_node_text(aes(label = name), size = 2, 
                 vjust = 1, hjust = 1, 
                 check_overlap = TRUE) +
  theme(legend.position = "none") + 
  labs(title = "Network graphs of Reliefweb bigrams related to the Ukraine conflict in 2022", 
       subtitle = "Data source: https://reliefweb.int/")

ggsave("network_graph.png", network_graph, width = 42, height = 29.7, units = "cm", dpi = 300)
  
```




